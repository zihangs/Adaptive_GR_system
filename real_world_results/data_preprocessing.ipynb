{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def reCreateDir(dirName):\n",
    "    # Check whether the specified path exists or not\n",
    "    isExist = os.path.exists(dirName)\n",
    "    if isExist:\n",
    "        # delete\n",
    "        shutil.rmtree(dirName)\n",
    "    \n",
    "    os.makedirs(dirName)\n",
    "    \n",
    "def writePlan(trace_df, file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        for activity in trace_df[\"Activity\"]:\n",
    "            file.write(activity.lower() + '\\n')\n",
    "        file.write(';cost\\n')\n",
    "\n",
    "\n",
    "########## group to traces #######\n",
    "# Replace 'your_file.csv' with the actual path to your CSV file\n",
    "csv_file_path = 'sepsis_cases_1.csv'\n",
    "\n",
    "# Read the CSV file line by line\n",
    "with open(csv_file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Create a list to store the rows\n",
    "data = []\n",
    "\n",
    "# Iterate through the lines and split them into columns\n",
    "for line in lines[1::]:\n",
    "    row = line.strip().split(';')  # Assuming comma-separated values\n",
    "    data.append(row)\n",
    "\n",
    "# Create a pandas DataFrame from the list of rows\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.columns = lines[0].strip().split(';')\n",
    "\n",
    "\n",
    "####### sort traces ###############\n",
    "curr_case_id = False\n",
    "t = False\n",
    "trace_time_tuple = []\n",
    "\n",
    "data_each_trace = []\n",
    "for index, row in df.iterrows():\n",
    "    case_id = row.loc['Case ID']\n",
    "    activity = row.loc['Activity']\n",
    "    label = row.loc['label']\n",
    "    last_t = t\n",
    "    t = row.loc['time:timestamp']\n",
    "    \n",
    "    if case_id != curr_case_id:\n",
    "\n",
    "        if data_each_trace:\n",
    "            dft = pd.DataFrame(data_each_trace)\n",
    "            dft.columns = ['Case ID', 'label', 'Activity', 'time:timestamp']\n",
    "            trace_time_tuple.append((last_t, dft))\n",
    "\n",
    "        data_each_trace = []\n",
    "        curr_case_id = case_id\n",
    "\n",
    "    data_each_trace.append([case_id, label, activity, t])\n",
    "        \n",
    "dft = pd.DataFrame(data_each_trace)\n",
    "dft.columns = ['Case ID', 'label', 'Activity', 'time:timestamp']\n",
    "trace_time_tuple.append((t, dft))\n",
    "\n",
    "sorted_tuples = sorted(trace_time_tuple, key=lambda x: x[0])\n",
    "\n",
    "\n",
    "############# group the traces in timeline order and group according to goal ###########\n",
    "inbalance_threshold = 5\n",
    "\n",
    "label_0 = []\n",
    "label_1 = []\n",
    "\n",
    "for tu in sorted_tuples:\n",
    "    if tu[1].iloc[0]['label'] == \"regular\" and len(label_0) - len(label_1) < 0:\n",
    "        label_0.append(tu[1])\n",
    "    if tu[1].iloc[0]['label'] == \"deviant\" and len(label_1) - len(label_0) < inbalance_threshold:\n",
    "        label_1.append(tu[1])\n",
    "        \n",
    "      \n",
    "    \n",
    "############ generate training and testing datasets ############\n",
    "    \n",
    "reCreateDir(\"training\")\n",
    "reCreateDir(\"training/goal_0\")\n",
    "reCreateDir(\"training/goal_1\")\n",
    "reCreateDir(\"testing\")\n",
    "\n",
    "trainSize = 10\n",
    "\n",
    "traceCount = 0\n",
    "for tr in label_0:\n",
    "    traceCount += 1\n",
    "    if traceCount <= trainSize:\n",
    "        file_path = \"training/goal_0/sas_plan.%s\" % str(traceCount)\n",
    "    else:\n",
    "        file_path = \"testing/sas_plan_0.%s\" % str( (traceCount-10)*2 - 1 )\n",
    "    writePlan(tr, file_path)\n",
    "    \n",
    "traceCount = 0\n",
    "for tr in label_1:\n",
    "    traceCount += 1\n",
    "    if traceCount <= trainSize:\n",
    "        file_path = \"training/goal_1/sas_plan.%s\" % str(traceCount)\n",
    "    else:\n",
    "        file_path = \"testing/sas_plan_1.%s\" % str( (traceCount-10)*2 )\n",
    "    writePlan(tr, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console. Set system property 'org.apache.logging.log4j.simplelog.StatusLogger.level' to TRACE to show Log4j2 internal initialization logging.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MineDFM: training/goal_0.xes.pnml    Success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console. Set system property 'org.apache.logging.log4j.simplelog.StatusLogger.level' to TRACE to show Log4j2 internal initialization logging.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MineDFM: training/goal_1.xes.pnml    Success!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################# convert to XES and mine the model ###################\n",
    "\n",
    "os.system(\"java -jar ../sas2xes.jar training/goal_0 training/goal_0.xes\")\n",
    "os.system(\"java -cp ../miner.jar autoMiner -DFM training/goal_0.xes training/goal_0.xes.pnml 0.8\")\n",
    "\n",
    "\n",
    "os.system(\"java -jar ../sas2xes.jar training/goal_1 training/goal_1.xes\")\n",
    "os.system(\"java -cp ../miner.jar autoMiner -DFM training/goal_1.xes training/goal_1.xes.pnml 0.8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import shutil\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "def func_precision(stringList, answer):\n",
    "    goal_count = 0\n",
    "    found = 0\n",
    "    for result in stringList:\n",
    "        if result == str(answer):\n",
    "            found = 1\n",
    "        goal_count += 1\n",
    "\n",
    "    return found/(goal_count-1)\n",
    "\n",
    "def func_recall(stringList, answer):\n",
    "    found = 0\n",
    "    for result in stringList:\n",
    "        if result == str(answer):\n",
    "            found = 1\n",
    "            break\n",
    "    return found\n",
    "\n",
    "def func_accuracy(total, stringList, answer):\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    for result in stringList[0:-1]:\n",
    "        if result == str(answer):\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    \n",
    "    fn = 1 - tp\n",
    "    \n",
    "    # total is the number of all goals\n",
    "    tn = total - tp - fp - fn\n",
    "    return (tp + tn)/(tn + tp + fp + fn)\n",
    "\n",
    "\n",
    "def func_bacc(total, stringList, answer):\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    for result in stringList[0:-1]:\n",
    "        if result == str(answer):\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    \n",
    "    fn = 1 - tp\n",
    "    \n",
    "    # total is the number of all goals\n",
    "    tn = total - tp - fp - fn\n",
    "\n",
    "    tpr = tp/(tp + fn)\n",
    "    tnr = tn/(tn + fp)\n",
    "    bacc = (tpr + tnr)/2\n",
    "\n",
    "    return bacc\n",
    "\n",
    "\n",
    "# return a list of each statistics for every testing case\n",
    "def calculate_statistics(rows):\n",
    "    length = rows.shape[0]\n",
    "\n",
    "    precision = []\n",
    "    recall = []\n",
    "    accuracy = []\n",
    "    b_accuracy = []\n",
    "        \n",
    "    for index, row in rows.iterrows():\n",
    "        \n",
    "        answer = row[\"Real_Goal\"]\n",
    "        results = row[\"Results\"].split(\"/\")\n",
    "        all_candidates = row[\"Cost\"].split(\"/\")\n",
    "        \n",
    "        total = len(all_candidates)-1   # the last one is /\n",
    "        \n",
    "        p = func_precision(results, answer)\n",
    "        r = func_recall(results, answer)\n",
    "        a = func_accuracy(total, results, answer)\n",
    "        bacc = func_bacc(total, results, answer)\n",
    "        \n",
    "        precision.append(p)\n",
    "        recall.append(r)\n",
    "        accuracy.append(a)\n",
    "        b_accuracy.append(bacc)\n",
    "    \n",
    "    return precision, recall, accuracy, b_accuracy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no relearn:\n",
      "0.7125\n",
      "0.6515151515151515\n",
      "open loop relearn:\n",
      "0.75\n",
      "0.7121212121212122\n",
      "closed loop ave relearn:\n",
      "0.7125\n",
      "0.7575757575757576\n",
      "closed loop trend relearn:\n",
      "0.7125\n",
      "0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "# sepsis 2 delete middle\n",
    "rdf = pd.read_csv(\"results_sepsis_2/out-no-relearn-sepsis_cases_2_%s.csv\" % obs)\n",
    "p, r, a, bacc = calculate_statistics(rdf)\n",
    "\n",
    "ori_acc = statistics.mean(bacc[0:40])\n",
    "\n",
    "print(\"no relearn:\" )\n",
    "print(statistics.mean(bacc[0:40]) )\n",
    "print(statistics.mean(bacc[161:200]) )\n",
    "\n",
    "rdf = pd.read_csv(\"results_sepsis_2/out-openloop-sepsis_cases_2_%s.csv\" % obs)\n",
    "p, r, a, bacc = calculate_statistics(rdf)\n",
    "print(\"open loop relearn:\" )\n",
    "print(statistics.mean(bacc[0:40]) )\n",
    "print(statistics.mean(bacc[161:200]) )\n",
    "\n",
    "rdf = pd.read_csv(\"results_sepsis_2/out-closedloop_ave_metric-sepsis_cases_2_%s.csv\" % obs)\n",
    "p, r, a, bacc = calculate_statistics(rdf)\n",
    "print(\"closed loop ave relearn:\" )\n",
    "print(statistics.mean(bacc[0:40]) )\n",
    "print(statistics.mean(bacc[161:200]) )\n",
    "\n",
    "rdf = pd.read_csv(\"results_sepsis_2/out-closedloop-trend-sepsis_cases_2_%s.csv\" % obs)\n",
    "p, r, a, bacc = calculate_statistics(rdf)\n",
    "print(\"closed loop trend relearn:\" )\n",
    "print(statistics.mean(bacc[0:40]) )\n",
    "print(statistics.mean(bacc[161:200]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no relearn:\n",
      "0.54\n",
      "0.42424242424242425\n",
      "open loop relearn:\n",
      "0.58\n",
      "0.5656565656565656\n",
      "closed loop ave relearn:\n",
      "0.57\n",
      "0.5353535353535354\n",
      "closed loop trend relearn:\n",
      "0.61\n",
      "0.601010101010101\n"
     ]
    }
   ],
   "source": [
    "obs = 1.0\n",
    "# BPIC11_f2\n",
    "rdf = pd.read_csv(\"results_BPIC11_f2/out-no-relearn-BPIC11_f2_%s.csv\"  % obs)\n",
    "p, r, a, bacc = calculate_statistics(rdf)\n",
    "print(\"no relearn:\" )\n",
    "print(statistics.mean(bacc[0:100]) )\n",
    "print(statistics.mean(bacc[101:200]) )\n",
    "\n",
    "rdf = pd.read_csv(\"results_BPIC11_f2/out-openloop-BPIC11_f2_%s.csv\"  % obs)\n",
    "p, r, a, bacc = calculate_statistics(rdf)\n",
    "print(\"open loop relearn:\" )\n",
    "print(statistics.mean(bacc[0:100]) )\n",
    "print(statistics.mean(bacc[101:200]) )\n",
    "\n",
    "rdf = pd.read_csv(\"results_BPIC11_f2/out-closedloop_ave_metric-BPIC11_f2_%s.csv\" % obs)\n",
    "p, r, a, bacc = calculate_statistics(rdf)\n",
    "print(\"closed loop ave relearn:\" )\n",
    "print(statistics.mean(bacc[0:100]) )\n",
    "print(statistics.mean(bacc[101:200]) )\n",
    "\n",
    "rdf = pd.read_csv(\"results_BPIC11_f2/out-closedloop-trend-BPIC11_f2_%s.csv\" % obs)\n",
    "p, r, a, bacc = calculate_statistics(rdf)\n",
    "print(\"closed loop trend relearn:\" )\n",
    "print(statistics.mean(bacc[0:100]) )\n",
    "print(statistics.mean(bacc[101:200]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no relearn:\n",
      "0.72\n",
      "0.6363636363636364\n",
      "open loop relearn:\n",
      "0.665\n",
      "0.7272727272727273\n",
      "closed loop ave relearn:\n",
      "0.72\n",
      "0.7171717171717171\n",
      "closed loop trend relearn:\n",
      "0.665\n",
      "0.7323232323232324\n"
     ]
    }
   ],
   "source": [
    "# hospital 3\n",
    "rdf = pd.read_csv(\"results_hospital_3/out-no-relearn-hospital_billing_3_%s.csv\"  % obs)\n",
    "p, r, a, bacc = calculate_statistics(rdf)\n",
    "print(\"no relearn:\" )\n",
    "print(statistics.mean(bacc[0:100]) )\n",
    "print(statistics.mean(bacc[101:200]) )\n",
    "\n",
    "rdf = pd.read_csv(\"results_hospital_3/out-openloop-hospital_billing_3_%s.csv\"  % obs)\n",
    "p, r, a, bacc = calculate_statistics(rdf)\n",
    "print(\"open loop relearn:\" )\n",
    "print(statistics.mean(bacc[0:100]) )\n",
    "print(statistics.mean(bacc[101:200]) )\n",
    "\n",
    "rdf = pd.read_csv(\"results_hospital_3/out-closedloop_ave_metric-hospital_billing_3_%s.csv\"  % obs)\n",
    "p, r, a, bacc = calculate_statistics(rdf)\n",
    "print(\"closed loop ave relearn:\" )\n",
    "print(statistics.mean(bacc[0:100]) )\n",
    "print(statistics.mean(bacc[101:200]) )\n",
    "\n",
    "rdf = pd.read_csv(\"results_hospital_3/out-closedloop-trend-hospital_billing_3_%s.csv\"  % obs)\n",
    "p, r, a, bacc = calculate_statistics(rdf)\n",
    "print(\"closed loop trend relearn:\" )\n",
    "print(statistics.mean(bacc[0:100]) )\n",
    "print(statistics.mean(bacc[101:200]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
